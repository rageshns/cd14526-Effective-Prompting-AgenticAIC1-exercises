{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 1: Role-Based Prompting (Agent Personas)\n",
    "\n",
    "## Historical Figure Interviewer\n",
    "\n",
    "In this hands-on exercise, you will craft prompts to instruct an AI to convincingly adopt the persona of a historical figure during an interactive Q&A session.\n",
    "\n",
    "## **Outline:**\n",
    "- Plain Prompt: Try a basic prompt without any specific role defined\n",
    "- Baseline Historical Figure Prompt: Ask the AI to role-play as a historical figure\n",
    "- Define Persona-Specific Attributes: Define personality, etc.\n",
    "- Add Tone and Style Specifications: Specify tone and style for the responses\n",
    "- Q&A Session Format: Conduct mock Q&A sessions to test persona consistency\n",
    "- Reflection & Transfer: Evaluate realism of AI responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using the Vocareum API endpoint\n",
    "# TODO: Fill in the missing parts marked with **********\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openai.vocareum.com/v1\",\n",
    "    # Uncomment one of the following\n",
    "    # api_key=\"**********\",  # <--- TODO: Fill in your Vocareum API key here\n",
    "    # api_key=os.getenv(\n",
    "    #     \"OPENAI_API_KEY\"\n",
    "    # ),  # <-- Alternately, set as an environment variable\n",
    ")\n",
    "\n",
    "# If using OpenAI's API endpoint\n",
    "# client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to display responses as Markdown, horizontally\n",
    "def display_responses(*args):\n",
    "    markdown_string = \"<table><tr>\"\n",
    "    # Headers\n",
    "    for arg in args:\n",
    "        markdown_string += f\"<th>System Prompt:<br />{arg['system_prompt']}<br /><br />\"\n",
    "        markdown_string += f\"User Prompt:<br />{arg['user_prompt']}</th>\"\n",
    "    markdown_string += \"</tr>\"\n",
    "    # Rows\n",
    "    markdown_string += \"<tr>\"\n",
    "    for arg in args:\n",
    "        markdown_string += f\"<td>Response:<br />{arg['response']}</td>\"\n",
    "    markdown_string += \"</tr></table>\"\n",
    "    display(Markdown(markdown_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to interact with the OpenAI API\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class OpenAIModels(str, Enum):\n",
    "    GPT_4O_MINI = \"gpt-4o-mini\"\n",
    "    GPT_41_MINI = \"gpt-4.1-mini\"\n",
    "    GPT_41_NANO = \"gpt-4.1-nano\"\n",
    "\n",
    "\n",
    "MODEL = OpenAIModels.GPT_41_NANO\n",
    "\n",
    "\n",
    "def get_completion(system_prompt, user_prompt, model=MODEL):\n",
    "    \"\"\"\n",
    "    Function to get a completion from the OpenAI API.\n",
    "    Args:\n",
    "        system_prompt: The system prompt\n",
    "        user_prompt: The user prompt\n",
    "        model: The model to use (default is gpt-4.1-mini)\n",
    "    Returns:\n",
    "        The completion text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Plain Prompt\n",
    "\n",
    "First, let's see what the model produces with a basic prompt before asking it to role-play as a historical figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_system_prompt = \"You are a helpful assistant.\"\n",
    "user_prompt = \"Can you tell me about relativity?\"\n",
    "\n",
    "print(f\"Sending prompt to {MODEL} model...\")\n",
    "control_response = get_completion(control_system_prompt, user_prompt)\n",
    "print(\"Response received!\\n\")\n",
    "\n",
    "display_responses(\n",
    "    {\n",
    "        \"system_prompt\": control_system_prompt,\n",
    "        \"user_prompt\": user_prompt,\n",
    "        \"response\": control_response,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline Historical Figure Prompt\n",
    "\n",
    "First, let's see what the model produces with a basic prompt asking it to role-play as Albert Einstein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add a role-based prompt for portraying Albert Einstein where you see the **********\n",
    "baseline_system_prompt = \"**********.\"\n",
    "user_prompt = \"Can you tell me about relativity?\"\n",
    "\n",
    "print(f\"Sending prompt to {MODEL} model...\")\n",
    "baseline_response = get_completion(baseline_system_prompt, user_prompt)\n",
    "print(\"Response received!\\n\")\n",
    "\n",
    "display_responses(\n",
    "    {\n",
    "        \"system_prompt\": baseline_system_prompt,\n",
    "        \"user_prompt\": user_prompt,\n",
    "        \"response\": baseline_response,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Persona-Specific Attributes (3 min)\n",
    "\n",
    "Now, let's enhance the prompt by adding specific attributes about Einstein's personality, era-specific vocabulary, and expertise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add persona-specific attributes where you see **********\n",
    "persona_system_prompt = f\"\"\"{baseline_system_prompt}.\n",
    "\n",
    "Adopt these persona characteristics:\n",
    "\n",
    "- Personality: **********\n",
    "- Speech style: **********\n",
    "- Expertise: **********\n",
    "- Historical context: **********\n",
    "  \n",
    "Answer as if you are Einstein speaking in 1950, reflecting on your life and work.\n",
    "Only discuss information that would have been known to you in your lifetime.\"\"\"\n",
    "\n",
    "user_prompt = \"Can you tell me about relativity?\"\n",
    "\n",
    "print(f\"Sending prompt to {MODEL} model...\")\n",
    "persona_response = get_completion(persona_system_prompt, user_prompt)\n",
    "print(\"Response received!\\n\")\n",
    "\n",
    "# Show last two prompts and responses\n",
    "display_responses(\n",
    "    {\n",
    "        \"system_prompt\": baseline_system_prompt,\n",
    "        \"user_prompt\": user_prompt,\n",
    "        \"response\": baseline_response,\n",
    "    },\n",
    "    {\n",
    "        \"system_prompt\": persona_system_prompt,\n",
    "        \"user_prompt\": user_prompt,\n",
    "        \"response\": persona_response,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Add Tone and Style Specifications (3 min)\n",
    "\n",
    "Let's further refine the prompt by adding specifications for tone and conversational style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add tone and style specifications where you see **********\n",
    "tone_system_prompt = f\"\"\"{persona_system_prompt}\n",
    "\n",
    "Tone and style:\n",
    "- **********\n",
    "- **********\n",
    "- **********\n",
    "\n",
    "Answer as if you are Einstein speaking in 1950, reflecting on your life and work. Only discuss\n",
    "information that would have been known to you in your lifetime.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"Can you tell me about relativity?\"\n",
    "\n",
    "print(\"Sending prompt with tone and style specifications...\")\n",
    "tone_response = get_completion(tone_system_prompt, user_prompt)\n",
    "print(\"Response received!\\n\")\n",
    "\n",
    "# Display the last two prompts and responses\n",
    "display_responses(\n",
    "    {\n",
    "        \"system_prompt\": persona_system_prompt,\n",
    "        \"user_prompt\": user_prompt,\n",
    "        \"response\": persona_response,\n",
    "    },\n",
    "    {\n",
    "        \"system_prompt\": tone_system_prompt,\n",
    "        \"user_prompt\": user_prompt,\n",
    "        \"response\": tone_response,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Q&A Session Format (2 min)\n",
    "\n",
    "Now, let's incorporate a specific Q&A format to test the persona consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add three questions where you see **********\n",
    "user_prompt = \"\"\"\n",
    "Questions:\n",
    "1. **********\n",
    "2. **********\n",
    "3. **********\n",
    "\"\"\"\n",
    "\n",
    "print(\"Sending prompt with Q&A format...\")\n",
    "qa_response = get_completion(tone_system_prompt, user_prompt)\n",
    "print(\"Response received!\\n\")\n",
    "\n",
    "display_responses(\n",
    "    {\n",
    "        \"system_prompt\": tone_system_prompt,\n",
    "        \"user_prompt\": user_prompt,\n",
    "        \"response\": qa_response,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Reflection & Transfer (5 min)\n",
    "\n",
    "Let's reflect on what we've learned from this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which prompt refinement produced the most authentic historical persona and why?\n",
    "\n",
    "Use this cell to jot down your thoughts:\n",
    "\n",
    "`TODO: Add your response where you see **********`\n",
    "\n",
    "Response: `**********`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this exercise, we explored how role-based prompting can be used to create convincing historical figure personas:\n",
    "\n",
    "1. **Plain Prompt**: We started with a simple request involving no role-playing.\n",
    "2. **Baseline Prompt**: We then used a simple request for the AI to role-play as Albert Einstein.\n",
    "3. **Persona-Specific Attributes**: We added details about personality traits, speech style, expertise, and historical context.\n",
    "4. **Tone and Style**: We further refined the prompt with specific instructions about conversational tone and linguistic style.\n",
    "5. **Q&A Format**: We tested the persona with specific questions to evaluate consistency and authenticity.\n",
    "\n",
    "Great work on making it this far! ðŸŽ‰ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
