{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2: Chain-of-Thought and ReACT Prompting\n",
    "\n",
    "## Demand‚ÄëSpike Detective for Retail Promotions\n",
    "\n",
    "In this hands-on exercise, you will guide an LLM to explain an unexpected sales spike--probing promotions data, competitor-pricing changes, and weather shifts--and then recommend the right inventory response for the retail chain.\n",
    "Outline:\n",
    "\n",
    "- Setup\n",
    "- Understand SKU‚Äëlevel sales data, promotional calendars, etc. \n",
    "- Craft a CoT prompt that has the LLM hypothesize causes based on data provided.\n",
    "- Create a ReACT prompt that can call a (simulated) weather‚ÄëAPI tool when the model suspects weather as a driver. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Let's start by setting up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "# No changes needed in this cell\n",
    "\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "from enum import Enum\n",
    "import os\n",
    "from lesson_2_lib import (\n",
    "    get_competitor_pricing_data,\n",
    "    get_sales_data,\n",
    "    get_promotions_data,\n",
    "    get_weather_data,\n",
    "    call_weather_api,\n",
    "    print_in_box,\n",
    ")\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using the Vocareum API endpoint\n",
    "# TODO: Fill in the missing parts marked with **********\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openai.vocareum.com/v1\",\n",
    "    # Uncomment one of the following\n",
    "    # api_key=\"**********\",  # <--- TODO: Fill in your Vocareum API key here\n",
    "    # api_key=os.getenv(\n",
    "    #     \"OPENAI_API_KEY\"\n",
    "    # ),  # <-- Alternately, set as an environment variable\n",
    ")\n",
    "\n",
    "# If using OpenAI's API endpoint\n",
    "# client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up helper functions\n",
    "# No changes needed in this cell\n",
    "\n",
    "\n",
    "class OpenAIModels(str, Enum):\n",
    "    GPT_4O_MINI = \"gpt-4o-mini\"\n",
    "    GPT_41_MINI = \"gpt-4.1-mini\"\n",
    "    GPT_41_NANO = \"gpt-4.1-nano\"\n",
    "\n",
    "\n",
    "MODEL = OpenAIModels.GPT_41_MINI\n",
    "\n",
    "\n",
    "def get_completion(system_prompt, user_prompt, model=MODEL):\n",
    "    \"\"\"\n",
    "    Function to get a completion from the OpenAI API.\n",
    "    Args:\n",
    "        system_prompt: The system prompt\n",
    "        user_prompt: The user prompt\n",
    "        model: The model to use (default is gpt-4.1-mini)\n",
    "    Returns:\n",
    "        The completion text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_completion_messages(messages, model=MODEL, temperature=0.1):\n",
    "    # Check that all messages are of the right form\n",
    "    for message in messages:\n",
    "        if (\n",
    "            not isinstance(message, dict)\n",
    "            or \"role\" not in message\n",
    "            or \"content\" not in message\n",
    "            or message[\"role\"] not in [\"system\", \"user\", \"assistant\"]\n",
    "        ):\n",
    "            raise ValueError(f\"Message is not valid: {message!r}\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def display_responses(*args, user_prompt_limit=500):\n",
    "    \"\"\"Helper function to display responses as Markdown, horizontally.\"\"\"\n",
    "    markdown_string = \"<table><tr>\"\n",
    "    # Headers\n",
    "    for arg in args:\n",
    "        markdown_string += f\"<th>System Prompt:<br />{arg['system_prompt']}<br /><br />\"\n",
    "        markdown_string += f\"User Prompt:<br />{arg['user_prompt'][:user_prompt_limit]}\"\n",
    "        if len(arg[\"user_prompt\"]) > user_prompt_limit:\n",
    "            markdown_string += \"... [truncated]\"\n",
    "        markdown_string += \"</th>\"\n",
    "    markdown_string += \"</tr>\"\n",
    "    # Rows\n",
    "    markdown_string += \"<tr>\"\n",
    "    for arg in args:\n",
    "        markdown_string += f\"<td>Response:<br />{arg['response']}</td>\"\n",
    "    markdown_string += \"</tr></table>\"\n",
    "    display(Markdown(markdown_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understand SKU-level sales data, promotional calendars, etc.\n",
    "\n",
    "First, let's review the sample data provided. Working with AI Agents is still a data problem at its core, so the first steps are always to understand the business goals (explain the cause for the spike) and the underlying data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the simulated data\n",
    "# No changes needed in this cell\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "sales_data = get_sales_data()\n",
    "sales_df = pd.DataFrame(sales_data)\n",
    "\n",
    "promotions_data = get_promotions_data()\n",
    "promotions_df = pd.DataFrame(promotions_data)\n",
    "\n",
    "weather_data = get_weather_data()\n",
    "weather_df = pd.DataFrame(weather_data)\n",
    "\n",
    "competitor_pricing_data = get_competitor_pricing_data()\n",
    "competitor_pricing_df = pd.DataFrame(competitor_pricing_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the sales data\n",
    "# No changes needed in this cell\n",
    "\n",
    "sales_df = sales_df.sort_values(by=[\"product_id\", \"date\"]).reset_index(drop=True)\n",
    "sales_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the promotions data\n",
    "# No changes needed in this cell\n",
    "\n",
    "promotions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the weather data\n",
    "# No changes needed in this cell\n",
    "\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the competitor pricing data\n",
    "# No changes needed in this cell\n",
    "\n",
    "competitor_pricing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph the sales data\n",
    "# No changes needed in this cell\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "for product_id, product_data in sales_df.groupby(\"product_id\"):\n",
    "    product_data.sort_values(by=\"date\", inplace=True)\n",
    "    plt.plot(product_data[\"date\"], product_data[\"quantity\"], label=product_id)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Quantity\")\n",
    "plt.title(\"Sales Data for Each Product\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the weather data\n",
    "\n",
    "weather_df[\"temperature_c\"] = weather_df[\"temperature\"].apply(lambda x: x[\"celsius\"])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(weather_df[\"date\"], weather_df[\"temperature_c\"])\n",
    "\n",
    "# For each day, add the value of \"main\" in text\n",
    "for i, row in weather_df.iterrows():\n",
    "    # Add a transparent background to the text\n",
    "    plt.text(\n",
    "        row[\"date\"],\n",
    "        row[\"temperature_c\"],\n",
    "        row[\"conditions\"][\"main\"],\n",
    "        backgroundcolor=\"white\",\n",
    "    )\n",
    "\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Temperature\")\n",
    "plt.title(\"Weather Data for Each Day\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the competitor pricing data\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "for competitor in [\"a\", \"b\", \"c\"]:\n",
    "    for product in competitor_pricing_df[\"product\"].unique():\n",
    "        plt.plot(\n",
    "            competitor_pricing_df[competitor_pricing_df[\"product\"] == product][\"date\"],\n",
    "            competitor_pricing_df[competitor_pricing_df[\"product\"] == product][\n",
    "                f\"competitor_{competitor}_price\"\n",
    "            ],\n",
    "            label=f\"{product} - competitor {competitor.upper()}\",\n",
    "            color=f\"C{product[-1]}\",\n",
    "        )\n",
    "plt.xlabel(\"Date\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Price\")\n",
    "plt.title(\"Competitor Prices for Each Product\")\n",
    "# Put the legend outside the plot\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflect on the sales data\n",
    "\n",
    "`TODO: Insert your reflection here`\n",
    "\n",
    "Reflection: The sales data shows a clear pattern of sales spikes for Product 5 on January 12th, which is the same day as a promotion. There was a promotion, \"Weekend Special\", which started on January 12th, but that was for Product 2.\n",
    "\n",
    "Looking ahead we see that the weather was fluctuating between below freezing and above freezing. On the 12th in particular, there was heavy rain.\n",
    "\n",
    "Competitor pricing is a bit harder to look at, but if we isolate it to Product 5, we see that the price for one competitor dropped on January 12th, which may have led to more overall consumer interest in that product or may have coincided an ad campaign.\n",
    "\n",
    "In practice, a human would look at all these factors and more to determine the cause of the sales spike by digging deeper, investigating all possible causes.\n",
    "\n",
    "Let's see if we can get this far with a CoT prompt, which should at least find the sales spike and not assume this promotion is responsible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Craft a simple CoT prompt\n",
    "\n",
    "Let's start with a simple CoT prompt. We won't tell the model to which steps to follow. We also won't use any tools in this example.\n",
    "\n",
    "<div style=\"color: red\">Note: Modern LLMs such as GPT-4.1 may not need an explicit \"think in steps\" phrase or instructions to think in steps, as this behavior can be added to a model in its fine-tuning process. In fact, some models such as o1 may refuse to respond to prompts that ask for CoT. Consider running your prompts with and without asking for CoT explicitly.</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill in the part marked with ********** with a phrase such as \"Think step by step.\"\n",
    "# Feel free to try variations!\n",
    "\n",
    "system_prompt_explicit_cot = \"\"\"\n",
    "You are a meticulous Retail Demand Analyst.\n",
    "Your task is to analyze provided sales data and promotion schedules to identify and explain significant sales spikes for specific SKUs.\n",
    "\n",
    "**********\n",
    "\"\"\"\n",
    "\n",
    "system_prompt_no_explicit_cot = \"\"\"\n",
    "You are a meticulous Retail Demand Analyst.\n",
    "Your task is to analyze provided sales data and promotion schedules to identify and explain significant sales spikes for specific SKUs.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt_analyze = f\"\"\"\n",
    "Analyze the data provided below and hypothesize causes for any observed sales spikes.\n",
    "\n",
    "Sales Data:\n",
    "{sales_data}\n",
    "\n",
    "Promotions Calendar:\n",
    "{promotions_data}\n",
    "\n",
    "Weather Data:\n",
    "{weather_data}\n",
    "\n",
    "Competitor Pricing Data:\n",
    "{competitor_pricing_data}\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Sending prompt to {MODEL} model...\")\n",
    "explicit_cot_response_1 = get_completion(\n",
    "    system_prompt_explicit_cot, user_prompt_analyze\n",
    ")\n",
    "no_explicit_cot_response_2 = get_completion(\n",
    "    system_prompt_no_explicit_cot, user_prompt_analyze\n",
    ")\n",
    "print(\"Response received!\\n\")\n",
    "\n",
    "# We compare the explicit CoT and non-ex\n",
    "display_responses(\n",
    "    {\n",
    "        \"system_prompt\": system_prompt_explicit_cot,\n",
    "        \"user_prompt\": user_prompt_analyze,\n",
    "        \"response\": explicit_cot_response_1,\n",
    "    },\n",
    "    {\n",
    "        \"system_prompt\": system_prompt_no_explicit_cot,\n",
    "        \"user_prompt\": user_prompt_analyze,\n",
    "        \"response\": no_explicit_cot_response_2,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "- What did you notice about the output of this CoT prompt?\n",
    "- What were the differences between including CoT and not including CoT explicitly in the prompt?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Craft a More Developed CoT Prompt\n",
    "\n",
    "Let's add more to our CoT prompt. Let's ask the model to follow a specific set of steps in an instructions section. This may help us not only get final answers that align with our needs, but it will also help us constrain the output to a more specific format.\n",
    "\n",
    "Finally, we'd like to the model to get the single largest spike and hypothesize its causes, using the following output format:\n",
    "\n",
    "````\n",
    "\n",
    "STRUCTURED ANALYSIS:\n",
    "[Structured Analysis]\n",
    "\n",
    "LARGEST SPIKE:\n",
    "```json\n",
    "{\n",
    "    \"date\": \"YYYY-MM-DD\",\n",
    "    \"amount\": \"X.XX\",\n",
    "    \"percentage\": \"X.XX%\"\n",
    "    \"causes\": [\n",
    "        \"Cause 1\",\n",
    "        \"Cause 2\",\n",
    "        \"Cause 3\"\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add some more components to our CoT Prompt\n",
    "# TODO: Replace parts marked with a **********\n",
    "\n",
    "system_prompt_cot = \"\"\"\n",
    "You are a meticulous Retail Demand Analyst.\n",
    "Your task is to analyze provided sales data and promotion schedules to identify and explain significant sales spikes for specific SKUs.\n",
    "\n",
    "Think in steps.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt_analyze = f\"\"\"\n",
    "## INSTRUCTIONS:\n",
    "\n",
    "Analyze the data provided below and hypothesize causes for any observed sales spikes.\n",
    "\n",
    "Instructions:\n",
    "* Find all sales spikes for each product\n",
    "* For each product, identify the following:\n",
    "    * Date of the sales spike\n",
    "    * Amount of the sales spike and percentage increase\n",
    "    * Possible causes of the sales spike according to the provided\n",
    "        * sales data\n",
    "        * promotion schedule\n",
    "        * weather conditions\n",
    "        * competitor pricing data\n",
    "* Start with your analysis\n",
    "* Conclude with the single largest spike according to the percentage increase with a short explanation for it.\n",
    "\n",
    "--\n",
    "\n",
    "## OUTPUT FORMAT:\n",
    "\n",
    "STRUCTURED ANALYSIS:\n",
    "[Structured Analysis]\n",
    "\n",
    "LARGEST SPIKE:\n",
    "```json\n",
    "{{\n",
    "    \"date\": \"YYYY-MM-DD\",\n",
    "    \"amount\": \"X.XX\",\n",
    "    \"percentage\": \"X.XX%\"\n",
    "    \"causes\": [\n",
    "        \"Cause 1\",\n",
    "        \"Cause 2\",\n",
    "        \"Cause 3\"\n",
    "    ]\n",
    "}}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## CONTEXT\n",
    "\n",
    "Sales Data:\n",
    "{sales_data}\n",
    "\n",
    "Promotions Calendar:\n",
    "{promotions_data}\n",
    "\n",
    "Weather Data:\n",
    "{weather_data}\n",
    "\n",
    "Competitor Pricing Data:\n",
    "{competitor_pricing_data}\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Sending prompt to {MODEL} model...\")\n",
    "cot_response = get_completion(system_prompt_cot, user_prompt_analyze)\n",
    "print(\"Response received!\\n\")\n",
    "\n",
    "\n",
    "def parse_analysis_and_largest_spike(response):\n",
    "    import json\n",
    "\n",
    "    if \"LARGEST SPIKE:\\n```json\" not in response:\n",
    "        print()\n",
    "        print(response)\n",
    "        raise RuntimeError(\n",
    "            \" ‚ùå No LARGEST SPIKE found in response. Looking for: \\n\\n LARGEST SPIKE:\\n```json\"\n",
    "        )\n",
    "\n",
    "    analysis = response.split(\"LARGEST SPIKE:\\n```json\")[0].strip()\n",
    "    json_str = response.split(\"LARGEST SPIKE:\\n```json\")[1].split(\"```\")[0].strip()\n",
    "    return analysis, json.loads(json_str)\n",
    "\n",
    "\n",
    "analysis, largest_spike = parse_analysis_and_largest_spike(cot_response)\n",
    "\n",
    "display(Markdown(analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the largest spike\n",
    "# No changes needed in this cell\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(largest_spike)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "- Did the model follow your instructions?\n",
    "- How was the description of the highest spike by percentage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a ReACT prompt that can call a (simulated) weather‚ÄëAPI tool\n",
    "\n",
    "While it is often convenient to throw all of the data into the prompt for the model to figure it out, sometimes the entire dataset is too large or too complex for the model to handle. In this case, we may want our model to be able to decide when to call a tool with what parameters.\n",
    "\n",
    "When requesting the usage of a tool, the model will return a special output, signaling the orchestrator to call the tool (e.g. `tool_call: weather_api`). The orchestrator will then call the tool and put the result in the message history for the model to use.\n",
    "\n",
    "Let's create a prompt that will have the model follow the ReACT pattern of Think, Act, Observe, and then repeat until it has a final answer.\n",
    "\n",
    "For this exercise we will use the following tools:\n",
    "\n",
    "### Available Tools\n",
    "* `noop()`: Do nothing. Useful if you are not ready to take a tool call.\n",
    "* `calculator(expression: str)`: Perform an arithmetic calculation\n",
    "    - Example:\n",
    "        - Input: `ACT: calculator(expression=\"(10 + 20) / 2.0\")`\n",
    "        - Output: `OBSERVE: 15.0`\n",
    "* `get_sales_data()`: Get the sales data\n",
    "    - Example:\n",
    "        - Input: `ACT: get_sales_data()`\n",
    "        - Output: `OBSERVE: {\"date\": \"2024-01-10\", \"product_id\": \"P001\", \"product_name\": \"Product 1\", \"quantity\": 255, \"revenue\": 15547.35}`\n",
    "* `call_weather_api(date: str)`: Get weather data for a specific date. Call this for the date of each spike.\n",
    "    - Example:\n",
    "        - Input: `ACT: call_weather_api(date=\"2024-01-10\")`\n",
    "        - Output: `OBSERVE: {\"date\": \"2024-01-10\", \"weather\": \"Sunny\", \"temperature\": 72}`\n",
    "\n",
    "* `final_answer(amount: str, causes: list[str], date: str, percentage: str)`: Return the final answer\n",
    "    - Example:\n",
    "        - Input: `ACT: final_answer(amount=\"32\", causes=[\"Competitor X offering a 29 discount boosting category interest\", ...], date=\"2020-06-12\", percentage=\"20.00%\")`\n",
    "        - Output: `OBSERVE: {\"amount\": \"32\", \"causes\": [\"Competitor X offering a 29 discount boosting category interest\", ...], \"date\": \"2020-06-12\", \"percentage\": \"20.00%\"}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's create a ReACT prompt that will run for a single step.\n",
    "# It should conclude with asking for a tool call.\n",
    "# TODO: Replace parts marked with a **********\n",
    "\n",
    "\n",
    "react_system_prompt = \"\"\"\n",
    "You are a meticulous Retail Demand Analyst that can solve any TASK in a multi-step process using tool calls and reasoning.\n",
    "\n",
    "## Instructions:\n",
    "- You will use step-by-step reasoning by\n",
    "    - THINKING the next steps to take to complete the task and what next tool call to take to get one step closer to the final answer\n",
    "    - ACTING on the single next tool call to take\n",
    "- You will always respond with a single THINK/ACT message of the following format:\n",
    "    THINK:\n",
    "    **********\n",
    "    ACT:\n",
    "    **********\n",
    "- As soon as you know the final answer, call the `final_answer` tool in an `ACT` message.\n",
    "- ********** <--- Extra instructions\n",
    "\n",
    "\n",
    "## Available Tools\n",
    "**********\n",
    "\n",
    "You will not use any other tools.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "--USER MESSAGE--\n",
    "TASK:\n",
    "Respond to the query \"What was the weather one week ago?\". Today is 2024-01-17.\n",
    "\n",
    "--ASSISTANT MESSAGE--\n",
    "THINK:\n",
    "********** <-- Finish the message history until the end of the loop\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "user_prompt_analyze = \"\"\"\n",
    "TASK: Find the single largest sales spike according to the percentage increase with a short explanation for it\n",
    "based on factors such as weather.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Sending prompt to {MODEL} model...\")\n",
    "\n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": react_system_prompt})\n",
    "messages.append({\"role\": \"user\", \"content\": user_prompt_analyze})\n",
    "\n",
    "react_response = get_completion_messages(messages)\n",
    "\n",
    "messages.append({\"role\": \"assistant\", \"content\": react_response})\n",
    "print(\"Response received!\\n\")\n",
    "\n",
    "\n",
    "for message in messages:\n",
    "    if message[\"role\"] == \"system\":\n",
    "        continue\n",
    "    print_in_box(message[\"content\"], title=f\"{message['role'].capitalize()}\")\n",
    "\n",
    "assert \"ACT:\" in messages[-1][\"content\"], (\n",
    "    \" ‚ùå No ACT message found in response. Looking for: \\n\\n ACT:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tool Calling Parsing and Calling\n",
    "\n",
    "Awesome! Let's now work on our functions that will parse the text following the `ACT:` part of the response and call a pre-defined function.\n",
    "\n",
    "As a reminder, here are the tools we wish to support:\n",
    "\n",
    "### Available Tools\n",
    "* `noop()`: Do nothing. Useful if you are not ready to take a tool call.\n",
    "* `calculator(expression: str)`: Perform an arithmetic calculation\n",
    "    - Example:\n",
    "        - Input: `ACT: calculator(expression=\"(10 + 20) / 2.0\")`\n",
    "        - Output: `OBSERVE: 15.0`\n",
    "* `get_sales_data()`: Get the sales data\n",
    "    - Example:\n",
    "        - Input: `ACT: get_sales_data()`\n",
    "        - Output: `OBSERVE: {\"date\": \"2024-01-10\", \"product_id\": \"P001\", \"product_name\": \"Product 1\", \"quantity\": 255, \"revenue\": 15547.35}`\n",
    "* `call_weather_api(date: str)`: Get weather data for a specific date. Call this for the date of each spike.\n",
    "    - Example:\n",
    "        - Input: `ACT: call_weather_api(date=\"2024-01-10\")`\n",
    "        - Output: `OBSERVE: {\"date\": \"2024-01-10\", \"weather\": \"Sunny\", \"temperature\": 72}`\n",
    "\n",
    "* `final_answer(amount: str, causes: list[str], date: str, percentage: str)`: Return the final answer\n",
    "    - Example:\n",
    "        - Input: `ACT: final_answer(amount=\"32\", causes=[\"Competitor X offering a 29 discount boosting category interest\", ...], date=\"2020-06-12\", percentage=\"20.00%\")`\n",
    "        - Output: `OBSERVE: {\"amount\": \"32\", \"causes\": [\"Competitor X offering a 29 discount boosting category interest\", ...], \"date\": \"2020-06-12\", \"percentage\": \"20.00%\"}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's work on our calculator function!\n",
    "# TODO: Replace parts marked with a **********\n",
    "\n",
    "import re\n",
    "\n",
    "import ast\n",
    "import operator\n",
    "\n",
    "\n",
    "def safe_eval(expr):\n",
    "    \"\"\"\n",
    "    Evaluate a mathematical expression safely.\n",
    "\n",
    "    We normally don't want to use eval() because it can execute arbitrary code, unless we are in a\n",
    "    properly sandboxed environment. This function is a safe alternative for evaluating mathematical\n",
    "    expressions.\n",
    "    \"\"\"\n",
    "    operators = {\n",
    "        ast.Add: operator.add,\n",
    "        ast.Sub: operator.sub,\n",
    "        ast.Mult: operator.mul,\n",
    "        ast.Div: operator.truediv,\n",
    "        ast.USub: operator.neg,\n",
    "    }\n",
    "\n",
    "    def eval_node(node):\n",
    "        if isinstance(node, ast.Constant):\n",
    "            return node.value\n",
    "        elif isinstance(node, ast.BinOp):\n",
    "            return operators[type(node.op)](eval_node(node.left), eval_node(node.right))\n",
    "        elif isinstance(node, ast.UnaryOp):\n",
    "            return operators[type(node.op)](eval_node(node.operand))\n",
    "        elif isinstance(node, ast.Expr):\n",
    "            return eval_node(node.value)\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported type: {type(node)}\")\n",
    "\n",
    "    return eval_node(ast.parse(expr, mode=\"eval\").body)\n",
    "\n",
    "\n",
    "def calculator(expression: str) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate a mathematical expression safely.\n",
    "    \"\"\"\n",
    "    return float(**********)  # TODO: Replace with a call to evaluate the expression\n",
    "\n",
    "\n",
    "assert (actual := calculator(\"10 + 10\")) == 20.0, f\" ‚ùå Expected 20.0, got {actual}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observation_message(response: str) -> str:\n",
    "    \"\"\"\n",
    "    Take a THINK/ACT response, run the tool call, and return the observation message.\n",
    "\n",
    "    Args:\n",
    "        response (str): The THINK/ACT response.\n",
    "\n",
    "    Returns:\n",
    "        str: The observation message.\n",
    "\n",
    "    Uses regular expressions to match the tool call and run the corresponding tool.\n",
    "\n",
    "    If the response is invalid, return an error message as a string that the agent can understand.\n",
    "    \"\"\"\n",
    "    from ast import literal_eval\n",
    "\n",
    "    observation_message = None\n",
    "\n",
    "    SALES_DATA_REGEX = r\"ACT:\\nget_sales_data\\(\\)\"\n",
    "    WEATHER_REGEX = r\"ACT:\\ncall_weather_api\\(date=\\\"(.*)\\\"\\)\"\n",
    "    CALCULATOR_REGEX = **********  # TODO: Add regex for calculator\n",
    "    FINAL_ANSWER_REGEX = r\"ACT:\\nfinal_answer\\(amount=\\\"(.*)\\\", causes=(.*), date=\\\"(.*)\\\", percentage=\\\"(.*)\\\"\\)\"\n",
    "    NOOP_REGEX = **********  # TODO: Add regex for noop\n",
    "\n",
    "    # TOOL 1: get_sales_data\n",
    "    if re.search(SALES_DATA_REGEX, response):\n",
    "        sales_data = get_sales_data(products=[\"P005\"])\n",
    "        # filter sales data to Product 5\n",
    "        sales_data = [\n",
    "            item for item in sales_data if item[\"product_name\"] == \"Product 5\"\n",
    "        ]\n",
    "        observation_message = f\"OBSERVE:\\n{sales_data}\"\n",
    "\n",
    "    # TOOL 2: call_weather_api\n",
    "    elif re.search(WEATHER_REGEX, response):\n",
    "        date = re.search(WEATHER_REGEX, response).groups()[0]\n",
    "        weather_data = call_weather_api(date)\n",
    "        observation_message = f\"OBSERVE:\\n{weather_data}\"\n",
    "\n",
    "    # TOOL 3: calculator\n",
    "    elif re.search(CALCULATOR_REGEX, response):\n",
    "        expression = re.search(CALCULATOR_REGEX, response).groups()[0]\n",
    "        observation_message = f\"OBSERVE:\\n{calculator(expression)}\"\n",
    "\n",
    "    # TOOL 4: final_answer\n",
    "    elif re.search(FINAL_ANSWER_REGEX, response):\n",
    "        amount, causes, date, percentage = re.search(\n",
    "            FINAL_ANSWER_REGEX,\n",
    "            response,\n",
    "        ).groups()\n",
    "        causes = literal_eval(causes)\n",
    "        observation_message = f\"OBSERVE:\\namount: {amount}\\ndate: {date}\\npercentage: {percentage}\\ncauses: {causes}\"\n",
    "\n",
    "    # TOOL 5: noop\n",
    "    elif re.search(NOOP_REGEX, response):\n",
    "        observation_message = \"OBSERVE:\\nNo action taken.\"\n",
    "\n",
    "    # Error\n",
    "    else:\n",
    "        observation_message = \"OBSERVE:\\nInvalid tool call or tool not supported.\"\n",
    "\n",
    "    return observation_message\n",
    "\n",
    "\n",
    "# Test cases\n",
    "assert (\n",
    "    actual := get_observation_message(\"\"\"\n",
    "THINK:\n",
    "[thinking here]\n",
    "ACT:\n",
    "get_sales_data()\n",
    "\"\"\")\n",
    ") == (expected := \"OBSERVE:\\n\" + str(get_sales_data(products=[\"P005\"]))), (\n",
    "    f\"{actual} != {expected}\"\n",
    ")\n",
    "\n",
    "assert (\n",
    "    actual := get_observation_message(\"\"\"\n",
    "THINK:\n",
    "[thinking here]\n",
    "ACT:\n",
    "call_weather_api(date=\"2024-01-12\")\n",
    "\"\"\")\n",
    ") == (expected := \"OBSERVE:\\n\" + str(call_weather_api(\"2024-01-12\"))), (\n",
    "    f\"{actual} != {expected}\"\n",
    ")\n",
    "\n",
    "assert (\n",
    "    actual := get_observation_message(\"\"\"\n",
    "THINK:\n",
    "[thinking here]\n",
    "ACT:\n",
    "final_answer(amount=\"10\", causes=[\"cause1\", \"cause2\"], date=\"2024-01-12\", percentage=\"10%\")\n",
    "\"\"\")\n",
    ") == (\n",
    "    expected\n",
    "    := \"OBSERVE:\\namount: 10\\ndate: 2024-01-12\\npercentage: 10%\\ncauses: ['cause1', 'cause2']\"\n",
    "), f\"{actual} != {expected}\"\n",
    "\n",
    "assert (\n",
    "    actual := get_observation_message(\"\"\"\n",
    "THINK:\n",
    "[thinking here]\n",
    "ACT:\n",
    "calculator(expression=\"10 + 10\")\n",
    "\"\"\")\n",
    ") == (expected := \"OBSERVE:\\n20.0\"), f\"{actual} != {expected}\"\n",
    "\n",
    "assert (\n",
    "    actual := get_observation_message(\"\"\"\n",
    "THINK:\n",
    "[thinking here]\n",
    "ACT:\n",
    "noop()\n",
    "\"\"\")\n",
    ") == (expected := \"OBSERVE:\\nNo action taken.\"), f\"{actual} != {expected}\"\n",
    "\n",
    "assert (\n",
    "    actual := get_observation_message(\"\"\"\n",
    "THINK:\n",
    "[thinking here]\n",
    "ACT:\n",
    "invalid_tool()\n",
    "\"\"\")\n",
    ") == (expected := \"OBSERVE:\\nInvalid tool call or tool not supported.\"), (\n",
    "    f\"{actual} != {expected}\"\n",
    ")\n",
    "\n",
    "assert (\n",
    "    actual := get_observation_message(\"\"\"\n",
    "THINK:\n",
    "[thinking here]\n",
    "ACT_TYPO:\n",
    "get_sales_data()\n",
    "\"\"\")\n",
    ") == (expected := \"OBSERVE:\\nInvalid tool call or tool not supported.\"), (\n",
    "    f\"{actual} != {expected}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Putting It All Together\n",
    "\n",
    "Now we're ready to put it all together! We will now use the ReACT prompt we created in the previous section to call a (simulated) weather API tool. This will run in a loop for a maximum number of iterations until the `final_answer` tool is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make the ReACT loop!\n",
    "# TODO: Replace instances of ********** where specified\n",
    "\n",
    "messages = []\n",
    "\n",
    "# ********** <-- Add the react_system_prompt to the message history\n",
    "# ********** <-- Add the user_prompt_analyze to the message history\n",
    "\n",
    "\n",
    "for message in messages:\n",
    "    if message[\"role\"] == \"system\":\n",
    "        continue\n",
    "    print_in_box(message[\"content\"], title=f\"{message['role'].capitalize()}\")\n",
    "\n",
    "num_react_steps = 0\n",
    "\n",
    "observation_message = None\n",
    "while True:\n",
    "    observation_message = None\n",
    "\n",
    "    num_action_retries = 0\n",
    "\n",
    "    while not observation_message:\n",
    "        react_response = ********** # <-- Get the completion response from the current messages\n",
    "        observation_message = ********** # <-- Call the tool and get the observation message\n",
    "        if observation_message is None:\n",
    "            print(f\"ERROR: Retrying... {num_action_retries}\")\n",
    "\n",
    "        num_action_retries += 1\n",
    "        if num_action_retries > 5:\n",
    "            break\n",
    "\n",
    "    messages.append({\"role\": \"assistant\", \"content\": react_response})\n",
    "    print_in_box(\n",
    "        react_response, title=f\"Assistant (Think + Act). Step {num_react_steps + 1}\"\n",
    "    )\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": observation_message})\n",
    "\n",
    "    if \"ACT:\\nfinal_answer\" in react_response:\n",
    "        print_in_box(observation_message, title=\"FINAL ANSWER\")\n",
    "        break\n",
    "\n",
    "    print_in_box(\n",
    "        observation_message, title=f\"User (Observe). Step {num_react_steps + 1}\"\n",
    "    )\n",
    "\n",
    "    num_react_steps += 1\n",
    "    if num_react_steps > **********:  # TODO: Add max number of React steps\n",
    "        print(\"ERROR: Max number of React steps exceeded. Breaking.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "Great work! Let's take a chance to think about what we've seen so far.\n",
    "\n",
    "- What can you say about the need to explicitly state \"Think in steps\" in a prompt for using Chain of Thought reasoning?\n",
    "- In what cases does using a single CoT prompt call work better than using a ReACT prompt and loop?\n",
    "- In what cases does it work the other way around?\n",
    "- In this case, which example was more efficient (faster, processed more data, etc.) and why?\n",
    "- Suppose you wanted to see if the LLM actually needed the calculator in the ReACT example. How would you modify the ReACT prompt to try it without the calculator?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "üéâ Congratulations! üéâ You've learned how to apply Chain-of-Thought and ReACT prompting techniques to retail analytics!\n",
    "\n",
    "Through this exercise, you've seen how to:\n",
    "\n",
    "- üìä Guide an LLM through structured reasoning about complex retail data\n",
    "- ü§î Implement Chain-of-Thought prompting to analyze potential causes of sales spikes\n",
    "- üîÑ Add ReACT components to incorporate external data validation\n",
    "\n",
    "Keep up the good work! üíØ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
