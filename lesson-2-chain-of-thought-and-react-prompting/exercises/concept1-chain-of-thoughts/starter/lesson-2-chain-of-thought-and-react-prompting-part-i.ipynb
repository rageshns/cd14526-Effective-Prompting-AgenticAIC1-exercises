{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2: Chain-of-Thought and ReACT Prompting\n",
    "\n",
    "## Demand‚ÄëSpike Detective, Part I: Chain-of-Thoughts\n",
    "\n",
    "In this hands-on exercise, you will guide an LLM to explain an unexpected sales spike.\n",
    "\n",
    "### Outline:\n",
    "- Setup\n",
    "- Understand sales data, promotional calendars, etc. \n",
    "- Craft a Simple CoT prompt\n",
    "- Craft a More Developed CoT Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Let's start by setting up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "# No changes needed in this cell\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display\n",
    "from lesson_2_lib import (\n",
    "    # Helpers\n",
    "    OpenAIModels,\n",
    "    display_responses,\n",
    "    # Synthetic data\n",
    "    get_competitor_pricing_data,\n",
    "    get_completion,\n",
    "    get_promotions_data,\n",
    "    get_sales_data,\n",
    "    get_weather_data,\n",
    ")\n",
    "from openai import OpenAI\n",
    "\n",
    "MODEL = OpenAIModels.GPT_41_NANO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using the Vocareum API endpoint\n",
    "# No changes needed in this cell\n",
    "# TODO: Fill in the missing parts marked with **********\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openai.vocareum.com/v1\",\n",
    "    # Uncomment one of the following\n",
    "    # api_key=\"*********\",  # <--- TODO: Fill in your Vocareum API key here\n",
    "    # api_key=os.getenv(\n",
    "    #     \"OPENAI_API_KEY\"\n",
    "    # ),  # <-- Alternately, set as an environment variable (more secure)\n",
    ")\n",
    "\n",
    "# If using OpenAI's API endpoint\n",
    "# client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understand sales data, promotional calendars, etc.\n",
    "\n",
    "First, let's review the sample data provided. Working with AI Agents is still a data problem at its core, so the first steps are always to understand the business goals (explain the cause for the spike) and the underlying data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the data\n",
    "get_sales_data()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the simulated data\n",
    "# No changes needed in this cell\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "sales_data = get_sales_data()\n",
    "sales_df = pd.DataFrame(sales_data)\n",
    "\n",
    "promotions_data = get_promotions_data()\n",
    "promotions_df = pd.DataFrame(promotions_data)\n",
    "\n",
    "weather_data = get_weather_data()\n",
    "weather_df = pd.DataFrame(weather_data)\n",
    "\n",
    "competitor_pricing_data = get_competitor_pricing_data()\n",
    "competitor_pricing_df = pd.DataFrame(competitor_pricing_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the sales data\n",
    "# No changes needed in this cell\n",
    "\n",
    "sales_df = sales_df.sort_values(by=[\"product_id\", \"date\"]).reset_index(drop=True)\n",
    "sales_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the promotions data\n",
    "# No changes needed in this cell\n",
    "\n",
    "promotions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the weather data\n",
    "# No changes needed in this cell\n",
    "\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the competitor pricing data\n",
    "# No changes needed in this cell\n",
    "\n",
    "competitor_pricing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph the sales data\n",
    "# No changes needed in this cell\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "for product_id, product_data in sales_df.groupby(\"product_id\"):\n",
    "    product_data.sort_values(by=\"date\", inplace=True)\n",
    "    plt.plot(product_data[\"date\"], product_data[\"quantity\"], label=product_id)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Quantity\")\n",
    "plt.title(\"Sales Data for Each Product\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, sales_df[\"quantity\"].max() + 10)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the weather data\n",
    "\n",
    "weather_df[\"temperature_c\"] = weather_df[\"temperature\"].apply(lambda x: x[\"celsius\"])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(weather_df[\"date\"], weather_df[\"temperature_c\"])\n",
    "\n",
    "# For each day, add the value of \"main\" in text\n",
    "for i, row in weather_df.iterrows():\n",
    "    # Add a transparent background to the text\n",
    "    plt.text(\n",
    "        row[\"date\"],\n",
    "        row[\"temperature_c\"],\n",
    "        row[\"conditions\"][\"main\"],\n",
    "        backgroundcolor=\"white\",\n",
    "    )\n",
    "\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Temperature\")\n",
    "plt.title(\"Weather Data for Each Day\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the competitor pricing data\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "for product in competitor_pricing_df[\"product\"].unique():\n",
    "    for competitor in [\"a\", \"b\", \"c\"]:\n",
    "        plt.plot(\n",
    "            competitor_pricing_df[competitor_pricing_df[\"product\"] == product][\"date\"],\n",
    "            competitor_pricing_df[competitor_pricing_df[\"product\"] == product][\n",
    "                f\"competitor_{competitor}_price\"\n",
    "            ],\n",
    "            label=f\"{product} - competitor {competitor.upper()}\",\n",
    "            color=f\"C{product[-1]}\",\n",
    "        )\n",
    "plt.xlabel(\"Date\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Price\")\n",
    "plt.ylim(0, competitor_pricing_df.filter(like=\"price\").max().max() + 10)\n",
    "plt.title(\"Competitor Prices for Each Product\")\n",
    "# Put the legend outside the plot\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflect on the sales data\n",
    "\n",
    "`TODO: Insert your reflection here`\n",
    "\n",
    "Reflection:\n",
    "\n",
    "* Sales spike for Product 5 on January 12th\n",
    "* The \"Weekend Special\" promotion which started on January 12th, but that was for Product 2. Still, it may have had an indirect effect on Product 5.\n",
    "* Weather was fluctuating between below freezing and above freezing. On the 12th in particular, there was heavy rain.\n",
    "* As for Competitor pricing, we see that Product 5's price for one competitor dropped on January 12th, which may have led to more overall consumer interest in that product or may have coincided with an ad campaign.\n",
    "\n",
    "In practice, a human would look at all these factors and more to determine the cause of the sales spike by digging deeper.\n",
    "\n",
    "Let's see if we can get this far with a CoT prompt, which should at least find the sales spike and provide some reasons similar to what we've observed as human beings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Craft a simple CoT prompt\n",
    "\n",
    "Let's start with a simple CoT prompt. We won't tell the model to which steps to follow. We also won't use any tools in this example.\n",
    "\n",
    "<div style=\"color: red\">Note: Many modern LLMs may not need an explicit \"think in steps\" phrase in order to think in steps before providing an answer, as this behavior can be included in training process. Consider running your prompts with and without asking for CoT explicitly. In fact, multiple runs may yield different results, so it's worth simply re-running the same prompts more than once.</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill in the part marked with ********** with a phrase such as \"Think step by step.\"\n",
    "# Feel free to try variations!\n",
    "\n",
    "system_prompt_explicit_cot = \"\"\"\n",
    "You are a meticulous Retail Demand Analyst.\n",
    "Your task is to analyze provided sales data and promotion schedules to identify and explain significant sales spikes for specific SKUs.\n",
    "\n",
    "**********\n",
    "\"\"\"\n",
    "\n",
    "system_prompt_no_explicit_cot = \"\"\"\n",
    "You are a meticulous Retail Demand Analyst.\n",
    "Your task is to analyze provided sales data and promotion schedules to identify and explain significant sales spikes for specific SKUs.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt_analyze = f\"\"\"\n",
    "Analyze the data provided below and hypothesize causes for any observed sales spikes.\n",
    "\n",
    "Sales Data:\n",
    "{sales_data}\n",
    "\n",
    "Promotions Calendar:\n",
    "{promotions_data}\n",
    "\n",
    "Weather Data:\n",
    "{weather_data}\n",
    "\n",
    "Competitor Pricing Data:\n",
    "{competitor_pricing_data}\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Sending prompt to {MODEL} model...\")\n",
    "explicit_cot_response_1 = get_completion(\n",
    "    system_prompt=system_prompt_explicit_cot, user_prompt=user_prompt_analyze,\n",
    "    model=MODEL,\n",
    "    client=client\n",
    ")\n",
    "no_explicit_cot_response_2 = get_completion(\n",
    "    system_prompt=system_prompt_no_explicit_cot, user_prompt=user_prompt_analyze,\n",
    "    model=MODEL,\n",
    "    client=client\n",
    ")\n",
    "print(\"Response received!\\n\")\n",
    "\n",
    "# We compare the explicit CoT and non-ex\n",
    "display_responses(\n",
    "    {\n",
    "        \"system_prompt\": system_prompt_explicit_cot,\n",
    "        \"user_prompt\": user_prompt_analyze,\n",
    "        \"response\": explicit_cot_response_1,\n",
    "    },\n",
    "    {\n",
    "        \"system_prompt\": system_prompt_no_explicit_cot,\n",
    "        \"user_prompt\": user_prompt_analyze,\n",
    "        \"response\": no_explicit_cot_response_2,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "- What were the differences between including CoT and not including CoT explicitly in the prompt?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Craft a More Developed CoT Prompt\n",
    "\n",
    "Let's add more to our CoT prompt. Let's ask the model to follow a specific set of steps in an **instructions section**. This may help us not only get final answers that align with our needs, but it will also help us constrain the output to a more specific format.\n",
    "\n",
    "Finally, we'd like to the model to identify the single largest spike and hypothesize its causes, using the following output format:\n",
    "\n",
    "````\n",
    "\n",
    "STRUCTURED ANALYSIS:\n",
    "[Structured Analysis]\n",
    "\n",
    "LARGEST SPIKE:\n",
    "```json\n",
    "{\n",
    "    \"date\": \"YYYY-MM-DD\",\n",
    "    \"amount_before_increase\": \"X.XX\",\n",
    "    \"amount_after_increase\": \"X.XX\",\n",
    "    \"percentage_increase\": \"X.XX%\",\n",
    "    \"causes\": [\n",
    "        \"Cause 1\",\n",
    "        \"Cause 2\",\n",
    "        \"Cause 3\"\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add some more components to our CoT Prompt\n",
    "# TODO: Replace parts marked with a **********\n",
    "\n",
    "system_prompt_cot = \"\"\"\n",
    "You are a meticulous Retail Demand Analyst.\n",
    "Your task is to analyze provided sales data and promotion schedules to identify and explain significant sales spikes for specific SKUs.\n",
    "\n",
    "Think in steps.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt_analyze = f\"\"\"\n",
    "## INSTRUCTIONS:\n",
    "\n",
    "Analyze the data provided below and hypothesize causes for any observed sales spikes.\n",
    "\n",
    "Instructions:\n",
    "**********\n",
    "\n",
    "--\n",
    "\n",
    "## OUTPUT FORMAT:\n",
    "\n",
    "**********\n",
    "\n",
    "---\n",
    "\n",
    "## CONTEXT\n",
    "\n",
    "Sales Data:\n",
    "{sales_data}\n",
    "\n",
    "Promotions Calendar:\n",
    "{promotions_data}\n",
    "\n",
    "Weather Data:\n",
    "{weather_data}\n",
    "\n",
    "Competitor Pricing Data:\n",
    "{competitor_pricing_data}\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Sending prompt to {MODEL} model...\")\n",
    "cot_response = get_completion(system_prompt=system_prompt_cot, user_prompt=user_prompt_analyze,\n",
    "                              model=MODEL, client=client)\n",
    "print(\"Response received!\\n\")\n",
    "\n",
    "\n",
    "def parse_analysis_and_largest_spike(response):\n",
    "    import json\n",
    "\n",
    "    if \"```json\" not in response:\n",
    "        print()\n",
    "        print(response)\n",
    "        raise RuntimeError(\n",
    "            \" ‚ùå No LARGEST SPIKE found in response. Looking for: \\n\\n```json\"\n",
    "        )\n",
    "\n",
    "    analysis = response.split(\"```json\")[0].strip()\n",
    "    json_str = response.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "    return analysis, json.loads(json_str)\n",
    "\n",
    "\n",
    "analysis, largest_spike = parse_analysis_and_largest_spike(cot_response)\n",
    "\n",
    "display(Markdown(analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the largest spike\n",
    "# No changes needed in this cell\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(largest_spike)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "- Did the model follow your instructions?\n",
    "- How was the description of the highest spike by percentage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "üéâ Congratulations! üéâ You've learned how to apply Chain-of-Thought to retail analytics!\n",
    "\n",
    "Through this exercise, you've seen how to:\n",
    "\n",
    "- üìä Guide an LLM through structured reasoning about complex retail data\n",
    "- ü§î Implement Chain-of-Thought prompting to analyze potential causes of sales spikes\n",
    "\n",
    "Keep up the good work! üíØ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
